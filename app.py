import re
import json
import html
import textwrap
from dataclasses import dataclass
from datetime import datetime
from typing import Dict, List, Optional, Tuple

import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup

# Optional: OpenAI (works if OPENAI_API_KEY exists in Streamlit Secrets)
try:
    from openai import OpenAI
except Exception:
    OpenAI = None


# =========================
# Helpers
# =========================
def today_yyyymmdd() -> str:
    return datetime.now().strftime("%Y%m%d")


def normalize_spaces(s: str) -> str:
    # rule: "ë‹¨ì–´ì™€ ':'ëŠ” í•œì¹¸ ë„ê¸°" -> "ë‹¨ì–´: ê°’" í˜•íƒœë¡œ ë³´ì •
    # ì˜ˆ) "í‚¤ì›Œë“œ:ê°’" -> "í‚¤ì›Œë“œ: ê°’"
    s = re.sub(r"([ê°€-í£A-Za-z0-9])\s*:\s*", r"\1: ", s)
    # ê³¼ë„í•œ ê³µë°± ì •ë¦¬
    s = re.sub(r"[ \t]+\n", "\n", s)
    s = re.sub(r"\n{3,}", "\n\n", s).strip()
    return s


def safe_slug_10chars(title: str) -> str:
    # íŒŒì¼ëª…ì— ë„£ì„ "ì œëª©ê°„ë‹¨ìš”ì•½ 10ì ì´ë‚´"
    t = re.sub(r"\s+", "", title)
    t = re.sub(r"[^\wê°€-í£]", "", t)
    return t[:10] if t else "ë¸”ë¡œê·¸ê¸€"


def keywords_from_csv(csv_text: str) -> List[str]:
    if not csv_text.strip():
        return []
    items = [x.strip() for x in csv_text.split(",")]
    items = [x for x in items if x]
    # ì¤‘ë³µ ì œê±°(ìˆœì„œ ìœ ì§€)
    seen = set()
    out = []
    for x in items:
        if x.lower() not in seen:
            out.append(x)
            seen.add(x.lower())
    return out


def ensure_30_hashtags(base: List[str], extra: List[str]) -> List[str]:
    seen = set()
    out = []
    for tag in base + extra:
        t = tag.strip()
        if not t:
            continue
        if not t.startswith("#"):
            t = "#" + t
        key = t.lower()
        if key not in seen:
            out.append(t)
            seen.add(key)
        if len(out) >= 30:
            break
    # ë¶€ì¡±í•˜ë©´ ë³´ì¶©
    filler = [
        "#ê²¨ìš¸ì½”ë””", "#ë´„ì½”ë””", "#ê°„ì ˆê¸°ì½”ë””", "#ì˜¤í”¼ìŠ¤ë£©", "#í•˜ê°ë£©", "#í•™êµìƒë‹´ë£©",
        "#ì²´í˜•ì»¤ë²„", "#ë°ì¼ë¦¬íŒ¨ì…˜", "#ì¤‘ë…„ì½”ë””", "#ë¯¸ì‹œë£©", "#ì‹¬í”Œë£©", "#ê¾¸ì•ˆê¾¸",
        "#ìŠ¤íƒ€ì¼ë§", "#ì½”ë””ì¶”ì²œ", "#ì—¬ì„±íŒ¨ì…˜", "#ì‡¼í•‘ëª°ì¶”ì²œ", "#ì˜¤ëŠ˜ì˜ì½”ë””", "#ë°ì¼ë¦¬ì½”ë””",
        "#ì¤‘ë…„ì—¬ì„±", "#40ëŒ€ì½”ë””", "#50ëŒ€ì½”ë””"
    ]
    for t in filler:
        if len(out) >= 30:
            break
        if t.lower() not in seen:
            out.append(t)
            seen.add(t.lower())
    return out[:30]


def html_wrap(title: str, body_md_like: str) -> str:
    # ì•„ì£¼ ê°€ë²¼ìš´ HTML ë˜í•‘(ë¸”ë¡œê·¸ ë¶™ì—¬ë„£ê¸°ìš©)
    # ë§ˆí¬ë‹¤ìš´ ì™„ì „ ë³€í™˜ì€ ì•„ë‹ˆê³ , ë¬¸ë‹¨/ë¦¬ìŠ¤íŠ¸/í‘œê°€ ë³´ê¸° ì¢‹ê²Œ ë“¤ì–´ê°€ë„ë¡ë§Œ ì²˜ë¦¬
    lines = body_md_like.splitlines()
    html_lines = []
    in_ul = False
    for line in lines:
        l = line.rstrip()
        if l.startswith("|") and l.endswith("|"):
            # í‘œëŠ” ë³„ë„ ì²˜ë¦¬: md table ê·¸ëŒ€ë¡œ ë‘ë©´ ë¸”ë¡œê·¸ì—ì„œ ê¹¨ì§ˆ ìˆ˜ ìˆì–´ HTML í…Œì´ë¸”ë¡œ ë³€í™˜ ì‹œë„
            # ê°„ë‹¨ ë³€í™˜: í‘œ ë¸”ë¡ì„ ëª¨ì•„ì„œ pandasë¡œ ë³€í™˜
            # ì—¬ê¸°ì„œëŠ” ë³´ìˆ˜ì ìœ¼ë¡œ pre ì²˜ë¦¬
            if in_ul:
                html_lines.append("</ul>")
                in_ul = False
            html_lines.append(f"<pre>{html.escape(l)}</pre>")
            continue

        if re.match(r"^\s*[-â€¢]\s+", l):
            if not in_ul:
                html_lines.append("<ul>")
                in_ul = True
            item = re.sub(r"^\s*[-â€¢]\s+", "", l)
            html_lines.append(f"<li>{html.escape(item)}</li>")
            continue
        else:
            if in_ul:
                html_lines.append("</ul>")
                in_ul = False

        if l.strip() == "":
            html_lines.append("<br/>")
        elif re.match(r"^#{1,6}\s+", l):
            level = len(l.split(" ")[0])
            txt = l[level+1:].strip()
            level = min(max(level, 2), 4)  # h2~h4 ì •ë„ë¡œ ì œí•œ
            html_lines.append(f"<h{level}>{html.escape(txt)}</h{level}>")
        elif l.startswith(">"):
            html_lines.append(f"<blockquote>{html.escape(l[1:].strip())}</blockquote>")
        else:
            html_lines.append(f"<p>{html.escape(l)}</p>")

    if in_ul:
        html_lines.append("</ul>")

    return f"""<!doctype html>
<html lang="ko">
<head>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>{html.escape(title)}</title>
</head>
<body>
{''.join(html_lines)}
</body>
</html>
"""


@dataclass
class ProductInfo:
    name: str = ""
    price: str = ""
    url: str = ""
    description_hint: str = ""
    size_spec: Optional[pd.DataFrame] = None
    reviews_hint: str = ""


def try_fetch_misharp_product(url: str, timeout: int = 10) -> ProductInfo:
    """
    ë¯¸ìƒµ ìƒì„¸ URLì´ ë“¤ì–´ì˜¤ë©´ ê°€ëŠ¥í•œ ë²”ìœ„ì—ì„œ ìƒí’ˆëª… ì •ë„ë§Œ ìë™ ì¶”ì¶œ ì‹œë„.
    (ì‚¬ì´íŠ¸ êµ¬ì¡°/ì°¨ë‹¨/ë¡œë”© ë°©ì‹ì— ë”°ë¼ ì‹¤íŒ¨í•  ìˆ˜ ìˆìœ¼ë‹ˆ, ì‹¤íŒ¨í•´ë„ ì•±ì€ ì •ìƒ ë™ì‘)
    """
    info = ProductInfo(url=url)
    if not url.strip():
        return info
    try:
        r = requests.get(url, timeout=timeout, headers={"User-Agent": "Mozilla/5.0"})
        r.raise_for_status()
        soup = BeautifulSoup(r.text, "lxml")

        # 1) title ê¸°ë°˜ ìƒí’ˆëª… íŒíŠ¸
        title = (soup.title.get_text(strip=True) if soup.title else "").strip()
        if title:
            # í”í•œ íŒ¨í„´ ì •ë¦¬
            title = re.sub(r"\s*-\s*ë¯¸ìƒµ.*$", "", title).strip()
            info.name = title[:60]

        # 2) og:title ìš°ì„ 
        og = soup.find("meta", property="og:title")
        if og and og.get("content"):
            info.name = og["content"].strip()[:60]

        # 3) ê°€ê²©(ìˆìœ¼ë©´)
        # ì‚¬ì´íŠ¸ë§ˆë‹¤ ë‹¤ë¦„ -> ìˆ«ì/ì› íŒ¨í„´ ê²€ìƒ‰(ì²« ë§¤ì¹­)
        text = soup.get_text(" ", strip=True)
        m = re.search(r"(\d{1,3}(?:,\d{3})+)\s*ì›", text)
        if m:
            info.price = m.group(1) + "ì›"

        # 4) ì„¤ëª… íŒíŠ¸(ë„ˆë¬´ ê¸¸ë©´ ìš”ì•½ìš©ìœ¼ë¡œë§Œ)
        # ìƒí’ˆ ìƒì„¸ í…ìŠ¤íŠ¸ ì¼ë¶€
        info.description_hint = text[:800]

    except Exception:
        # ì‹¤íŒ¨í•´ë„ ê·¸ëƒ¥ ë¹ˆ ê°’ ìœ ì§€
        pass
    return info


def build_misharp_prompt(
    platform: str,
    product_name: str,
    primary_kw: str,
    keywords: List[str],
    user_notes: str,
    product_url: str,
    size_spec_text: str,
    reviews_text: str
) -> str:
    # ì§€ì¹¨ ê·¸ëŒ€ë¡œë¥¼ ì‹œìŠ¤í…œê¸‰ í”„ë¡¬í”„íŠ¸ë¡œ ê°•í•˜ê²Œ ê³ ì •
    # (ë¯¸ìƒµ ê¸€ êµ¬ì¡°/ë¬¸ì¥ ì‹œì‘/ì¸ì‚¬ë§ ì²«ë¬¸ì¥/ë¬¸ë‹¨ ì—°ê²°/ìš”ì•½/CTA/í‘œ/í•´ì‹œíƒœê·¸/ìŠ¬ë¡œê±´ ë“±)
    kws_joined = ", ".join(keywords) if keywords else ""
    return f"""
ë„ˆëŠ” 20ë…„ì°¨ ì—¬ì„±ì˜ë¥˜ ì‡¼í•‘ëª° CEO(ë¯¸ìƒµ ëŒ€í‘œ)ì´ë©°, ë„¤ì´ë²„/ë‹¤ìŒ/êµ¬ê¸€ SEOì— ê°•í•œ ë¸”ë¡œê·¸ ì‘ê°€ë‹¤.
í”Œë«í¼: {platform}
ëª©í‘œ: [ë¯¸ìƒµ] + ì—¬ì„±ì˜ë¥˜ ê²€ìƒ‰ì—ì„œ ìƒìœ„ë…¸ì¶œì„ ë…¸ë¦¬ëŠ” 5,000ì ë‚´ì™¸ ë¸”ë¡œê·¸ ê¸€.

[ì ˆëŒ€ ê·œì¹™]
- ì²« ë¬¸ì¥ì€ ë°˜ë“œì‹œ ì•„ë˜ ê·¸ëŒ€ë¡œ ì‹œì‘:
"ì•ˆë…•í•˜ì„¸ìš”^^ ì¼ìƒë„ ìŠ¤íƒ€ì¼ë„ ë¯¸ìƒµì²˜ëŸ¼ ì‹¬í”Œí•˜ê²Œ! 20ë…„ì°¨ ì—¬ì„±ì˜ë¥˜ ì‡¼í•‘ëª° ë¯¸ìƒµ ëŒ€í‘œì…ë‹ˆë‹¤."
- ê·¸ ë‹¤ìŒ ë¬¸ì¥ì—ëŠ” 'ì‹œì¦Œ/ë‚ ì”¨/ì‹œê¸°' ì¸ì‚¬ë§ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì¶”ê°€.
- ê° ë¬¸ë‹¨ì˜ ì‹œì‘ì€ ë°˜ë“œì‹œ "ë¯¸ìƒµ {product_name}ì€(ëŠ”) " ìœ¼ë¡œ ì‹œì‘.
- ë¬¸ë‹¨ ì‚¬ì´ êµ¬ë¶„ì„ (--- ë“±) ê¸ˆì§€. ëŒ€ì‹  ê³µê° ìœ ë„ ì—°ê²°ë¬¸ì¥ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ê°€ë¼.
- ì½œë¡  í‘œê¸° ì‹œ "ë‹¨ì–´: ê°’"ìœ¼ë¡œ í•œ ì¹¸ ë„ì–´ì“°ê¸°.
- ì œëª©ì—ëŠ” ë°˜ë“œì‹œ "[ë¯¸ìƒµ]" í¬í•¨, ìƒìœ„ í‚¤ì›Œë“œ 1ê°œ í¬í•¨("{primary_kw}"), ì¹´í…Œê³ ë¦¬ í‚¤ì›Œë“œë¡œ SEO ìµœì í™”.
- ë§íˆ¬: ëŒ€ì¤‘ì /ìºì£¼ì–¼, ë•Œë¡œëŠ” ì‡¼í•‘í˜¸ìŠ¤íŠ¸ í†¤, ë•Œë¡œëŠ” ì˜¤í”„ë¼ì¸ ì˜·ê°€ê²Œ ì‚¬ì¥ë‹˜ í†¤.
- í•´ì‹œíƒœê·¸ëŠ” ë§¨ ëì— 30ê°œë¥¼ í•œ ì¤„ë¡œ.

[í•„ìˆ˜ ë¬¸ë‹¨ êµ¬ì„±(ìˆœì„œ ìœ ì§€)]
1) ìµœìƒë‹¨ ìš”ì•½(3~5ì¤„)
2) ì´ëŸ° ë¶„ë“¤ê»˜ ì¶”ì²œí•©ë‹ˆë‹¤(4050 ì²´í˜•/TPO) - ë¦¬ìŠ¤íŒ…
3) ì´ëŸ´ ë•Œ ìš”ê¸´í•´ìš” - ìƒí™© ë¦¬ìŠ¤íŒ…
4) (ìì—°ìŠ¤ëŸ¬ìš´ íƒ€ì´í‹€) ë””ìì¸/í•ì´ ì£¼ëŠ” ì´ì : ì²´í˜•ì»¤ë²„, ë‚ ì”¬í•´ ë³´ì„ ë“±
5) (ìì—°ìŠ¤ëŸ¬ìš´ íƒ€ì´í‹€) ì†Œì¬/ì°©ìš©ê°ì´ ì£¼ëŠ” ìƒí™œ ì† ì´ì : êµ¬ê¹€, í¸ì•ˆí•¨ ë“±
6) (ìì—°ìŠ¤ëŸ¬ìš´ íƒ€ì´í‹€) ê°€ê²©/ê°€ì¹˜ ë² ë„¤í•: í€„ë¦¬í‹° ëŒ€ë¹„ í•©ë¦¬ì 
7) ê³ ê° í›„ê¸° ë°˜ì‘ ìš”ì•½: í›„ê¸° í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ ìˆìœ¼ë©´ ì´ ë¬¸ë‹¨ì€ ì•„ì˜ˆ ì“°ì§€ ë§ ê²ƒ
8) í™œìš©ì„± ë° ì½”ë”” ì œì•ˆ(TPO ì—°ê²°)
9) (ìì—°ìŠ¤ëŸ¬ìš´ íƒ€ì´í‹€) ì´ ì•„ì´í…œ, ê¼­ ë§Œë‚˜ë³´ì„¸ìš”(ê³µê° CTA)
10) ì•„ì´í…œ ì‚¬ì´ì¦ˆ ìŠ¤í™ í‘œ(í‘œ í˜•íƒœ)
11) ì‚¬ì´ì¦ˆ ì¶”ì²œ í‘œ(ì²´í˜•ë³„ ì¶”ì²œ)
12) ìµœí•˜ë‹¨ [ìš”ì•½] 3ì¤„
13) ìš”ì•½ ë‹¤ìŒ ì¤„ì— ì¸ìš©ë°•ìŠ¤(>)ë¡œ í•„ìš”ì„± ê³µê° CTA
14) ë§ˆì§€ë§‰ ì¤„: "ì¼ìƒë„ ìŠ¤íƒ€ì¼ë„ ë¯¸ìƒµì²˜ëŸ¼, ì‹¬í”Œí•˜ê²Œ! MISHARP"
15) í•´ì‹œíƒœê·¸ 30ê°œ(í•„ìˆ˜ í¬í•¨)

[ì…ë ¥ ì •ë³´]
- ìƒí’ˆëª…: {product_name}
- ìƒí’ˆ URL: {product_url}
- í•µì‹¬ í‚¤ì›Œë“œ(ìš°ì„ ìˆœìœ„): {kws_joined}
- ì‚¬ìš©ì ì¶”ê°€ ë©”ëª¨/ì›ê³ :
{user_notes}

- ì‚¬ì´ì¦ˆ ìŠ¤í™(ì‚¬ìš©ì ì œê³µ):
{size_spec_text}

- í›„ê¸°(ì‚¬ìš©ì ì œê³µ):
{reviews_text}

[ì¶œë ¥]
- ì œëª© 1ê°œ
- ë³¸ë¬¸(ìœ„ êµ¬ì¡°)
- ë§¨ ë í•´ì‹œíƒœê·¸ 30ê°œ(í•œ ì¤„)
""".strip()


def build_general_prompt(platform: str, topic: str, keywords: List[str], notes: str) -> str:
    kws_joined = ", ".join(keywords) if keywords else ""
    return f"""
ë„ˆëŠ” {platform} SEOì— ìµœì í™”ëœ ë¸”ë¡œê·¸ ê¸€ì„ ì“°ëŠ” ì „ë¬¸ê°€ë‹¤.
ë¶„ëŸ‰: ì•½ 5,000ì.
í‚¤ì›Œë“œ: {kws_joined} (ë³¸ë¬¸ì— ê³¼í•˜ì§€ ì•Šê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ë¶„ì‚°)

[ê¸€ ì‹œì‘ ê³ ì •]
"ì•ˆë…•í•˜ì„¸ìš”, 000ì…ë‹ˆë‹¤. (ì‹œê¸°ì ìœ¼ë¡œ ì ì ˆí•œ ì¸ì‚¿ë§) ì˜¤ëŠ˜ì€ ({topic})ì— ëŒ€í•´ ì–˜ê¸°í•´ë³¼ê¹Œí•´ìš”."

[í•„ìˆ˜ êµ¬ì„±]
- ìµœìƒë‹¨ ê¸€ìš”ì•½(3~5ì¤„)
- ì¼ìƒì  ê³µê° ë¬¸ì œ ì œê¸°/ê³µê° ìœ ë„
- ë³¸ë¬¸(ë¬¸ë‹¨ë³„ ì†Œì œëª©ìœ¼ë¡œ êµ¬ì¡°í™”)
- ë§ˆì§€ë§‰ ìš”ì•½(3ì¤„)
- í•´ì‹œíƒœê·¸ 30ê°œ(í•œ ì¤„)
- ë§ˆì§€ë§‰ ì¸ì‚¬: "ì˜¤ëŠ˜ ì •ë³´ê°€ ë„ì›€ì´ ë˜ì—ˆìœ¼ë©´ í•©ë‹ˆë‹¤." ëŠë‚Œì˜ ì°½ì‘ ì¸ì‚¬ë§

[ì¶œë ¥]
- ì œëª© 1ê°œ
- ë³¸ë¬¸
- í•´ì‹œíƒœê·¸ 30ê°œ(í•œ ì¤„)
""".strip()


def call_openai(prompt: str) -> str:
    api_key = st.secrets.get("OPENAI_API_KEY", "").strip() if hasattr(st, "secrets") else ""
    model = st.secrets.get("OPENAI_MODEL", "gpt-5").strip() if hasattr(st, "secrets") else "gpt-5"

    if not api_key or OpenAI is None:
        # Fallback: ê·œì¹™ ê¸°ë°˜ â€œì„ì‹œ ê¸€â€ (í…ŒìŠ¤íŠ¸ìš©)
        return "(í…ŒìŠ¤íŠ¸ ëª¨ë“œ) OpenAI í‚¤ê°€ ì—†ì–´ ê·œì¹™ ê¸°ë°˜ ì„ì‹œ ê¸€ì„ ì¶œë ¥í•©ë‹ˆë‹¤.\n\n" + prompt[:1800]

    client = OpenAI(api_key=api_key)
    # Responses API ê¸°ë³¸ ì‚¬ìš© ì˜ˆì‹œëŠ” OpenAI ê³µì‹ Quickstartë¥¼ ë”°ë¦„
    resp = client.responses.create(
        model=model,
        input=prompt
    )
    return resp.output_text


def build_size_tables_default() -> Tuple[pd.DataFrame, pd.DataFrame]:
    spec = pd.DataFrame(
        [
            {"ì‚¬ì´ì¦ˆ": "FREE", "ì–´ê¹¨": "-", "ê°€ìŠ´": "-", "ì•”í™€": "-", "ì†Œë§¤": "-", "ì´ì¥": "-"},
            {"ì‚¬ì´ì¦ˆ": "S", "ì–´ê¹¨": "-", "ê°€ìŠ´": "-", "ì•”í™€": "-", "ì†Œë§¤": "-", "ì´ì¥": "-"},
            {"ì‚¬ì´ì¦ˆ": "M", "ì–´ê¹¨": "-", "ê°€ìŠ´": "-", "ì•”í™€": "-", "ì†Œë§¤": "-", "ì´ì¥": "-"},
            {"ì‚¬ì´ì¦ˆ": "L", "ì–´ê¹¨": "-", "ê°€ìŠ´": "-", "ì•”í™€": "-", "ì†Œë§¤": "-", "ì´ì¥": "-"},
        ]
    )
    rec = pd.DataFrame(
        [
            {"ì²´í˜•": "55", "ì¶”ì²œ": "S ë˜ëŠ” FREE(ìŠ¬ë¦¼/ì •í• ì„ í˜¸ ê¸°ì¤€)", "ì½”ë©˜íŠ¸": "ìƒì²´ ìŠ¬ë¦¼, ë‹¨ì •í• ì¶”ì²œ"},
            {"ì²´í˜•": "66", "ì¶”ì²œ": "M ë˜ëŠ” FREE", "ì½”ë©˜íŠ¸": "êµ°ì‚´ ì»¤ë²„ + í¸ì•ˆí•¨ ë°¸ëŸ°ìŠ¤"},
            {"ì²´í˜•": "66ë°˜~77", "ì¶”ì²œ": "L ë˜ëŠ” ì—¬ìœ í•", "ì½”ë©˜íŠ¸": "ìƒì²´/ë³µë¶€ ì—¬ìœ  ìˆê²Œ"},
        ]
    )
    return spec, rec


# =========================
# UI
# =========================
st.set_page_config(
    page_title="ë¯¸ìƒµ ë¸”ë¡œê·¸ ì½˜í…ì¸  ìƒì„±ê¸°",
    page_icon="ğŸ“",
    layout="wide"
)

st.markdown(
    """
    <style>
      .block-container { padding-top: 1.2rem; padding-bottom: 2.5rem; }
      .step-card {
        border: 1px solid rgba(0,0,0,0.08);
        border-radius: 16px;
        padding: 16px 18px;
        background: white;
      }
      .muted { color: rgba(0,0,0,0.55); font-size: 0.92rem; }
      .pill {
        display: inline-block;
        padding: 4px 10px;
        border-radius: 999px;
        background: rgba(0,0,0,0.05);
        margin-right: 6px;
        font-size: 0.86rem;
      }
      .big-title { font-size: 1.35rem; font-weight: 800; margin-bottom: 0.25rem; }
    </style>
    """,
    unsafe_allow_html=True
)

st.markdown('<div class="big-title">ğŸ“ ë¯¸ìƒµ ë¸”ë¡œê·¸ ì½˜í…ì¸  ìƒì„±ê¸°</div>', unsafe_allow_html=True)
st.markdown('<div class="muted">ë¸”ë¡œê·¸ ì„ íƒ â†’ ì£¼ì œ/URL ì…ë ¥ â†’ ê¸€ ìƒì„±(TXT/HTML/ë³µì‚¬) â†’ ì´ë¯¸ì§€/ë°œí–‰ â†’ ì¹´í”¼ë¼ì´íŠ¸</div>', unsafe_allow_html=True)

left, right = st.columns([1.0, 1.05], gap="large")

with left:
    st.markdown('<div class="step-card">', unsafe_allow_html=True)
    st.markdown("### 1) ë¸”ë¡œê·¸ ì„ íƒ")
    platform = st.radio(
        "í”Œë«í¼",
        ["ë„¤ì´ë²„(ë„¤ì´ë²„ SEO)", "í‹°ìŠ¤í† ë¦¬(ë‹¤ìŒ/ì¹´ì¹´ì˜¤ SEO)", "ë¸”ë¡œê±°(êµ¬ê¸€ SEO)"],
        horizontal=True
    )
    platform_key = "naver" if platform.startswith("ë„¤ì´ë²„") else ("tistory" if platform.startswith("í‹°ìŠ¤í† ë¦¬") else "blogger")
    st.markdown('</div>', unsafe_allow_html=True)

    st.markdown('<div class="step-card" style="margin-top:12px;">', unsafe_allow_html=True)
    st.markdown("### 2) ì£¼ì œ ì…ë ¥")
    post_type = st.selectbox("ê¸€ ìœ í˜•", ["ë¯¸ìƒµ íŒ¨ì…˜ ì•„ì´í…œ ê¸€", "ê¸°íƒ€ ì£¼ì œ ê¸€"])

    colA, colB = st.columns([1, 1], gap="small")
    with colA:
        product_url = st.text_input("ìƒí’ˆ URL (ì„ íƒ)", placeholder="https://misharp.co.kr/product/detail.html?product_no=...")
    with colB:
        topic_text = st.text_input("ì£¼ì œ/ìƒí’ˆëª… (í•„ìˆ˜)", placeholder="ì˜ˆ) ì†Œìš¸ í•˜ì´ë„¥ ë°˜ëª© ë‹ˆíŠ¸ / 40ëŒ€ ì¶œê·¼ë£© ì½”ë””")

    kw_csv = st.text_input("í‚¤ì›Œë“œ (','ë¡œ êµ¬ë¶„)", placeholder="ì˜ˆ) 40ëŒ€ì—¬ì„±ì˜ë¥˜, 50ëŒ€ì—¬ì„±ì˜ë¥˜, ì¶œê·¼ë£©, ë°ì¼ë¦¬ë£©, ì²´í˜•ì»¤ë²„")
    keywords = keywords_from_csv(kw_csv)

    notes = st.text_area(
        "ë‚´ìš© ì…ë ¥ (ê¸€ììˆ˜ ì œí•œ ì—†ìŒ / ìƒì„¸ì„¤ëª…/ì›ê³ /ë©”ëª¨ ë¶™ì—¬ë„£ê¸°)",
        height=220,
        placeholder="ì—¬ê¸°ì— ë¯¸ìƒµ ìƒì„¸í˜ì´ì§€ ì›ê³ , ì†Œì¬/í•/ì¶”ì²œìƒí™©, ê³ ê° FAQ ë“± ì›í•˜ëŠ” ì¬ë£Œë¥¼ ë„£ì–´ì£¼ì„¸ìš”."
    )
    st.caption("TIP) ìƒí’ˆ URL ìë™ ì¶”ì¶œì´ ì‹¤íŒ¨í•  ìˆ˜ ìˆìœ¼ë‹ˆ, ì¤‘ìš”í•œ ë‚´ìš©ì€ ìœ„ ì…ë ¥ì¹¸ì— ë¶™ì—¬ë„£ëŠ” ë°©ì‹ì´ ê°€ì¥ ì•ˆì „í•©ë‹ˆë‹¤.")
    st.markdown('</div>', unsafe_allow_html=True)

    st.markdown('<div class="step-card" style="margin-top:12px;">', unsafe_allow_html=True)
    st.markdown("### 3) (ì„ íƒ) ì‚¬ì´ì¦ˆ/í›„ê¸° ì…ë ¥")
    st.caption("í›„ê¸° ì—†ìœ¼ë©´ 'í›„ê¸° ìš”ì•½ ë¬¸ë‹¨'ì€ ìë™ìœ¼ë¡œ ì œì™¸ë˜ê²Œ í”„ë¡¬í”„íŠ¸ ê·œì¹™ì— í¬í•¨ë¼ ìˆìŠµë‹ˆë‹¤.")
    size_spec_text = st.text_area("ì‚¬ì´ì¦ˆ ìŠ¤í™ (í‘œë¡œ ë§Œë“¤ ì¬ë£Œ)", height=130, placeholder="ì˜ˆ) ì–´ê¹¨ë‹¨ë©´ 38 / ê°€ìŠ´ë‘˜ë ˆ 100 / ì´ì¥ 60 ...")
    reviews_text = st.text_area("í›„ê¸° í…ìŠ¤íŠ¸ (ìˆìœ¼ë©´ ë¶™ì—¬ë„£ê¸°)", height=130, placeholder="í›„ê¸° ì—¬ëŸ¬ ê°œë¥¼ ë¶™ì—¬ë„£ìœ¼ë©´ ìš”ì•½í•´ì¤ë‹ˆë‹¤. ì—†ìœ¼ë©´ ë¹„ì›Œë‘ì„¸ìš”.")
    st.markdown('</div>', unsafe_allow_html=True)

with right:
    st.markdown('<div class="step-card">', unsafe_allow_html=True)
    st.markdown("### 4) ê¸€ ìƒì„±")
    st.markdown(
        f"""
        <span class="pill">í”Œë«í¼: {platform}</span>
        <span class="pill">ìœ í˜•: {post_type}</span>
        <span class="pill">ë‚ ì§œ: {today_yyyymmdd()}</span>
        """,
        unsafe_allow_html=True
    )

    fetch_btn = st.button("ğŸ” (ì„ íƒ) URLì—ì„œ ìƒí’ˆëª… ìë™ ì¶”ì¶œ", use_container_width=True)
    if fetch_btn and product_url.strip():
        info = try_fetch_misharp_product(product_url.strip())
        if info.name:
            st.success(f"ì¶”ì¶œëœ ìƒí’ˆëª…: {info.name}")
            if not topic_text.strip():
                st.session_state["topic_autofill"] = info.name
        else:
            st.warning("ìë™ ì¶”ì¶œì´ ì‹¤íŒ¨í–ˆì–´ìš”. ì£¼ì œ/ìƒí’ˆëª… ì…ë ¥ì¹¸ì— ì§ì ‘ ì ì–´ì£¼ì‹œëŠ” ê²Œ ê°€ì¥ ì•ˆì „í•©ë‹ˆë‹¤.")

    # Autofill
    if "topic_autofill" in st.session_state and not topic_text.strip():
        topic_text = st.session_state["topic_autofill"]

    generate_btn = st.button("âœ¨ ê¸€ ìƒì„±í•˜ê¸°", type="primary", use_container_width=True)

    if generate_btn:
        if not topic_text.strip():
            st.error("ì£¼ì œ/ìƒí’ˆëª…(í•„ìˆ˜)ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            with st.spinner("ê¸€ ìƒì„± ì¤‘..."):
                primary_kw = keywords[0] if keywords else (topic_text.strip().split()[0] if topic_text.strip() else "ì—¬ì„±ì˜ë¥˜")
                if post_type == "ë¯¸ìƒµ íŒ¨ì…˜ ì•„ì´í…œ ê¸€":
                    prompt = build_misharp_prompt(
                        platform=platform,
                        product_name=topic_text.strip(),
                        primary_kw=primary_kw,
                        keywords=keywords,
                        user_notes=notes.strip(),
                        product_url=product_url.strip(),
                        size_spec_text=size_spec_text.strip(),
                        reviews_text=reviews_text.strip(),
                    )
                else:
                    prompt = build_general_prompt(
                        platform=platform,
                        topic=topic_text.strip(),
                        keywords=keywords,
                        notes=notes.strip()
                    )

                out_text = call_openai(prompt)
                out_text = normalize_spaces(out_text)

                # í•´ì‹œíƒœê·¸ ë³´ì •: ë°˜ë“œì‹œ 30ê°œ & í•„ìˆ˜ í¬í•¨(ë¯¸ìƒµ ê¸€ì¼ ë•Œ)
                if post_type == "ë¯¸ìƒµ íŒ¨ì…˜ ì•„ì´í…œ ê¸€":
                    required = ["#ë¯¸ìƒµ", "#ì—¬ì„±ì˜ë¥˜", "#ì¶œê·¼ë£©", "#ë°ì¼ë¦¬ë£©", "#ootd", "#40ëŒ€ì—¬ì„±ì˜ë¥˜", "#50ëŒ€ì—¬ì„±ì˜ë¥˜", "#ì¤‘ë…„ì—¬ì„±íŒ¨ì…˜"]
                else:
                    required = []

                # ë³¸ë¬¸ì— í•´ì‹œíƒœê·¸ê°€ ìˆë“  ì—†ë“ , ë§ˆì§€ë§‰ì— 30ê°œ í•œ ì¤„ë¡œ í™•ì • ì¶œë ¥
                extra = []
                # í‚¤ì›Œë“œ ê¸°ë°˜ íƒœê·¸ ì¶”ê°€
                for k in keywords[:25]:
                    extra.append("#" + re.sub(r"\s+", "", k))
                tags = ensure_30_hashtags(required, extra)

                # ë³¸ë¬¸ ëì— ì´ë¯¸ íƒœê·¸ê°€ ìˆìœ¼ë©´ ì¤‘ë³µë  ìˆ˜ ìˆìœ¼ë‹ˆ, "ë§ˆì§€ë§‰ í•´ì‹œíƒœê·¸ ì¤„"ì„ ê°•ì œ êµì²´
                out_text_wo_tags = re.sub(r"(#\S+\s*){8,}$", "", out_text, flags=re.MULTILINE).rstrip()
                out_text = out_text_wo_tags + "\n\n" + " ".join(tags)

                # ì¹´í”¼ë¼ì´íŠ¸ ê³ ì§€(í•œê¸€/ì˜ë¬¸) + ìŠ¬ë¡œê±´ì€ ë¯¸ìƒµ ê¸€ì€ ë³¸ë¬¸ ê·œì¹™ì—ë„ í¬í•¨ë˜ì–´ ìˆìœ¼ë‚˜, í•˜ë‹¨ ë³„ë„ í‘œì‹œë„ ì œê³µ
                copyright_kr = "â“’ ë¯¸ìƒµì»´í¼ë‹ˆ(MISHARP COMPANY). ë³¸ ì½˜í…ì¸ ì˜ ì €ì‘ê¶Œì€ ë¯¸ìƒµì»´í¼ë‹ˆì— ìˆìœ¼ë©°, ë¬´ë‹¨ ë³µì œÂ·ë°°í¬Â·ì „ì¬Â·2ì°¨ ê°€ê³µ ë° ìƒì—…ì  ì´ìš©ì„ ê¸ˆí•©ë‹ˆë‹¤."
                copyright_en = "â“’ MISHARP COMPANY. All rights reserved. Unauthorized copying, redistribution, republication, modification, or commercial use is strictly prohibited."

                st.session_state["generated_text"] = out_text
                st.session_state["generated_title"] = out_text.splitlines()[0].strip() if out_text.splitlines() else topic_text.strip()
                st.session_state["copyright_kr"] = copyright_kr
                st.session_state["copyright_en"] = copyright_en

            st.success("ìƒì„± ì™„ë£Œ! ì•„ë˜ì—ì„œ TXT/HTML/ë³µì‚¬ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.")

    if "generated_text" in st.session_state:
        title_guess = st.session_state.get("generated_title", topic_text.strip())
        content_text = st.session_state["generated_text"]

        st.markdown("#### âœ… ê²°ê³¼ (í…ìŠ¤íŠ¸)")
        st.text_area("ìƒì„±ëœ ê¸€ (ì—¬ê¸°ì„œ ì „ì²´ ì„ íƒ í›„ ë³µì‚¬ ê°€ëŠ¥)", value=content_text, height=360)

        st.markdown("#### âœ… HTML ì†ŒìŠ¤")
        html_doc = html_wrap(title_guess, content_text)
        st.code(html_doc, language="html")

        # TXT ë‹¤ìš´ë¡œë“œ(íŒŒì¼ëª…: ë‚ ì§œ+ì œëª©ìš”ì•½10ì)
        fname = f"{today_yyyymmdd()}_{safe_slug_10chars(title_guess)}.txt"
        st.download_button(
            "â¬‡ï¸ TXT ë‹¤ìš´ë¡œë“œ",
            data=(content_text + "\n\n" + st.session_state["copyright_kr"] + "\n" + st.session_state["copyright_en"]),
            file_name=fname,
            mime="text/plain",
            use_container_width=True
        )

        # HTML ë‹¤ìš´ë¡œë“œ
        fname_html = f"{today_yyyymmdd()}_{safe_slug_10chars(title_guess)}.html"
        st.download_button(
            "â¬‡ï¸ HTML ë‹¤ìš´ë¡œë“œ",
            data=html_doc,
            file_name=fname_html,
            mime="text/html",
            use_container_width=True
        )

        st.markdown("#### 5) ì¹´í”¼ë¼ì´íŠ¸ ê³ ì§€ (í•œê¸€/ì˜ë¬¸)")
        st.write(st.session_state["copyright_kr"])
        st.write(st.session_state["copyright_en"])

    st.markdown('</div>', unsafe_allow_html=True)

    st.markdown('<div class="step-card" style="margin-top:12px;">', unsafe_allow_html=True)
    st.markdown("### 6) ì´ë¯¸ì§€ ìƒì„± / ë°œí–‰ ë°”ë¡œê°€ê¸°")

    st.markdown("**ë¯¸ìƒµ ìƒì„¸í˜ì´ì§€ ì´ë¯¸ì§€ ì¶”ì¶œê¸°(ìë™ ZIP ìƒì„±):**")
    st.link_button("ğŸ–¼ï¸ misharp-image-crop-v1 ì—´ê¸°", "https://misharp-image-crop-v1.streamlit.app/", use_container_width=True)

    st.markdown("**ì €ì‘ê¶Œ ê±±ì • ì—†ëŠ” ì´ë¯¸ì§€ ì†ŒìŠ¤:**")
    c1, c2 = st.columns(2)
    with c1:
        st.link_button("Pexels (ë¬´ë£Œ)", "https://www.pexels.com/ko-kr/", use_container_width=True)
    with c2:
        st.link_button("Pixabay (ë¬´ë£Œ)", "https://pixabay.com/ko/", use_container_width=True)

    st.markdown("**ë°œí–‰ ë¡œê·¸ì¸ ë§í¬:**")
    b1, b2, b3 = st.columns(3)
    with b1:
        st.link_button("ë„¤ì´ë²„ ë¸”ë¡œê·¸ ë¡œê·¸ì¸", "https://nid.naver.com/nidlogin.login", use_container_width=True)
    with b2:
        st.link_button("í‹°ìŠ¤í† ë¦¬ ë¡œê·¸ì¸", "https://www.tistory.com/auth/login", use_container_width=True)
    with b3:
        st.link_button("Blogger ë¡œê·¸ì¸", "https://accounts.google.com/signin/v2/identifier?service=blogger", use_container_width=True)

    st.markdown('</div>', unsafe_allow_html=True)

st.caption("â€» ì´ ì•±ì€ í˜•ì¤€ë‹˜ì´ ì •ë¦¬í•œ ì œì‘ ì§€ì¹¨ì„ ê·¸ëŒ€ë¡œ ë°˜ì˜í•´, ì˜¤ë¥˜ê°€ ë‚˜ë„ 'í†µì§¸ë¡œ êµì²´' ë°©ì‹ìœ¼ë¡œ ì¦‰ì‹œ ìˆ˜ì • ê°€ëŠ¥í•˜ë„ë¡ ë‹¨ì¼ app.py ì¤‘ì‹¬ìœ¼ë¡œ êµ¬ì„±í–ˆìŠµë‹ˆë‹¤.")
